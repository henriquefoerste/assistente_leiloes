# Assistente de Leil√µes

Um sistema inteligente para coleta e consulta de dados de leil√µes de im√≥veis do Portal Zuk.

## üìã Vis√£o Geral

Este projeto combina web scraping e RAG (Retrieval-Augmented Generation) para automatizar a coleta e an√°lise de editais de leil√µes de im√≥veis, oferecendo uma interface de busca sem√¢ntica para consultar informa√ß√µes dos im√≥veis leiloados.

## üõ†Ô∏è Funcionalidades

- **Web Scraping**: Coleta automatizada de dados do Portal Zuk
- **Processamento de PDFs**: Extra√ß√£o de texto de editais de leil√£o
- **Busca Sem√¢ntica**: Sistema RAG para consultas inteligentes usando FAISS
- **Metadados Estruturados**: Armazenamento organizado de informa√ß√µes dos im√≥veis

## üèóÔ∏è Estrutura do Projeto

```
assistente_leiloes/
‚îú‚îÄ‚îÄ web_scrapping/          # M√≥dulo de coleta de dados
‚îÇ   ‚îî‚îÄ‚îÄ zuk_scrapper.py     # Script para scraping do Portal Zuk
‚îú‚îÄ‚îÄ rag/                    # Sistema de busca sem√¢ntica
‚îÇ   ‚îú‚îÄ‚îÄ ingest.py          # Processamento e indexa√ß√£o de documentos
‚îÇ   ‚îî‚îÄ‚îÄ ask.py             # Interface de consulta
‚îú‚îÄ‚îÄ leiloes/               # Dados coletados organizados por leil√£o
‚îÇ   ‚îî‚îÄ‚îÄ leilao_xxxxx_/     # Pasta de cada leil√£o com PDFs e metadados
‚îî‚îÄ‚îÄ requirements.txt       # Depend√™ncias do projeto
```

## üöÄ Como Usar

### 1. Instala√ß√£o
```bash
pip install -r requirements.txt
```

### 2. Coleta de Dados
Execute o scraper para coletar novos leil√µes:
```bash
cd web_scrapping
python zuk_scrapper.py
```

### 3. Indexa√ß√£o
Processe e indexe os documentos coletados:
```bash
cd rag
python ingest.py
```

### 4. Consulta
Fa√ßa consultas sem√¢nticas nos dados:
```bash
cd rag
python ask.py
```

## ÔøΩ Fluxo de Processamento

### 1. Pipeline de Ingest√£o de Dados
```mermaid
flowchart TD
    A[In√≠cio] --> B[Web Scraping - Portal Zuk]
    B --> C[Download PDFs dos Editais]
    C --> D[Salvar metadata.json por leil√£o]
    D --> E[Extrair texto por p√°gina com PyMuPDF]
    E --> F[Chunking 700 palavras com overlap 150]
    F --> G[Gerar embeddings com Sentence Transformers]
    F --> H[Anexar metadados: leil√£o_id, c√≥digo_zuk, pre√ßo, localiza√ß√£o]
    G --> I[Criar √≠ndice FAISS]
    H --> I
    I --> J[Persistir √≠ndice e chunks em disco]
    J --> K[Estat√≠sticas: tipos de im√≥veis e cidades]
    K --> L[Pronto para consultas]
```

### 2. Pipeline de Consulta
```mermaid
flowchart TD
    A[Cliente via CLI] --> B[Input: pergunta do usu√°rio]
    B --> C[Gerar embedding da pergunta]
    C --> D[Buscar top-k similares no FAISS]
    D --> E{Tem resultados relevantes?}
    E -- N√£o --> F[Responder: n√£o encontrado no contexto]
    E -- Sim --> G[Recuperar chunks com metadados]
    G --> H[Formatar resultados com contexto enriquecido]
    H --> I[Exibir: c√≥digo, pre√ßo, localiza√ß√£o, trecho do edital]
    I --> J[Log: lat√™ncia e IDs dos chunks]
    J --> K[Fim]
```

## ÔøΩüîç Exemplo de Consulta

```
Digite sua pergunta: apartamento vila independencia preco ate 200000
```

O sistema retornar√° informa√ß√µes relevantes com:
- C√≥digo do im√≥vel
- Pre√ßo
- Localiza√ß√£o (cidade/bairro)
- Trechos do edital
- N√∫mero da p√°gina no documento

## üì¶ Depend√™ncias Principais

- **Selenium**: Web scraping automatizado
- **PyMuPDF**: Processamento de arquivos PDF
- **FAISS**: Busca vetorial eficiente
- **Sentence Transformers**: Embeddings sem√¢nticos multil√≠ngues
- **FastAPI**: API web (planejado)

## üéØ Dados Coletados

Para cada leil√£o, o sistema coleta:
- Edital completo em PDF
- Metadados estruturados (pre√ßo, localiza√ß√£o, tipo)
- P√°gina HTML original
- Informa√ß√µes do comitente e tribunal

## ü§ñ Tecnologias

- Python 3.x
- FAISS para busca vetorial
- Transformers para embeddings
- Selenium WebDriver
- PyMuPDF para processamento de PDFs

---

> **Nota**: Este projeto destina-se ao estudo e an√°lise de dados p√∫blicos de leil√µes judiciais para fins educacionais e de pesquisa.
